{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27165a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "\n",
    "from aalpy.learning_algs import run_Lstar\n",
    "from aalpy.oracles import RandomWordEqOracle\n",
    "from aalpy.utils import load_automaton_from_file\n",
    "\n",
    "from RNN import get_model, Optimization\n",
    "from util import conformance_test, RNNSul\n",
    "\n",
    "from extract_dnp3 import *\n",
    "from automata_data_generation import AutomatonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2d40ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on captures-sample/dnp3-2.pcap\n",
      "Gathering streams.....\n",
      "Identified 946 TCP streams!\n",
      "Iterating over s treams.....\n",
      "Working on captures-sample/dnp3-1.pcap\n",
      "Gathering streams.....\n",
      "Identified 1 TCP streams!\n",
      "Iterating over s treams.....\n",
      "Working on captures-sample/dnp3.pcap\n",
      "Gathering streams.....\n",
      "Identified 8 TCP streams!\n",
      "Iterating over s treams.....\n",
      "Returned training data...\n"
     ]
    }
   ],
   "source": [
    "exp_name = 'dnp3'\n",
    "device = None\n",
    "\n",
    "num_training_samples = 400\n",
    "num_val_samples = 155\n",
    "\n",
    "automaton_data, input_al, output_al = generate_dnp3_data('captures-sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d5d2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OPERATE',\n",
       " 'WARM_RESTART',\n",
       " 'READ',\n",
       " 'DISABLE_UNSOLICITED',\n",
       " 'SELECT',\n",
       " 'WRITE',\n",
       " 'COLD_RESTART',\n",
       " 'ENABLE_UNSOLICITED',\n",
       " 'STOP_APPL',\n",
       " 'CONFIRM']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac519b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONFIRM', 'RESPONSE', 'UNSOLICITED_RESPONSE'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ba16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(automaton_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a152b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = automaton_data[:num_training_samples], automaton_data[num_training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e8cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_handler = AutomatonDataset(input_al, output_al, batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef78313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = data_handler.create_dataset(training_data), data_handler.create_dataset(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b40f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Training loss: 1.1257\t Validation loss: 1.0454\t Accuracy: 76.66%\n",
      "[2/100] Training loss: 0.9917\t Validation loss: 0.9158\t Accuracy: 96.35%\n",
      "[3/100] Training loss: 0.8606\t Validation loss: 0.7805\t Accuracy: 94.58%\n",
      "[4/100] Training loss: 0.7198\t Validation loss: 0.6317\t Accuracy: 94.58%\n",
      "[5/100] Training loss: 0.5653\t Validation loss: 0.4729\t Accuracy: 94.58%\n",
      "[6/100] Training loss: 0.4091\t Validation loss: 0.3304\t Accuracy: 94.58%\n",
      "[7/100] Training loss: 0.2837\t Validation loss: 0.2356\t Accuracy: 94.58%\n",
      "[8/100] Training loss: 0.2081\t Validation loss: 0.1860\t Accuracy: 94.58%\n",
      "[9/100] Training loss: 0.1694\t Validation loss: 0.1615\t Accuracy: 94.58%\n",
      "[10/100] Training loss: 0.1494\t Validation loss: 0.1483\t Accuracy: 94.58%\n",
      "[15/100] Training loss: 0.1169\t Validation loss: 0.1256\t Accuracy: 94.58%\n",
      "[20/100] Training loss: 0.1054\t Validation loss: 0.1177\t Accuracy: 94.58%\n",
      "[25/100] Training loss: 0.0978\t Validation loss: 0.1127\t Accuracy: 94.58%\n",
      "[30/100] Training loss: 0.0917\t Validation loss: 0.1088\t Accuracy: 94.58%\n",
      "[35/100] Training loss: 0.0863\t Validation loss: 0.1053\t Accuracy: 94.58%\n",
      "[40/100] Training loss: 0.0813\t Validation loss: 0.1023\t Accuracy: 94.58%\n",
      "[45/100] Training loss: 0.0767\t Validation loss: 0.0997\t Accuracy: 94.58%\n",
      "[50/100] Training loss: 0.0723\t Validation loss: 0.0973\t Accuracy: 94.58%\n",
      "[55/100] Training loss: 0.0682\t Validation loss: 0.0953\t Accuracy: 94.58%\n",
      "[60/100] Training loss: 0.0643\t Validation loss: 0.0936\t Accuracy: 96.35%\n",
      "[65/100] Training loss: 0.0607\t Validation loss: 0.0922\t Accuracy: 96.35%\n",
      "[70/100] Training loss: 0.0573\t Validation loss: 0.0911\t Accuracy: 96.35%\n",
      "[75/100] Training loss: 0.0542\t Validation loss: 0.0902\t Accuracy: 96.35%\n",
      "[80/100] Training loss: 0.0513\t Validation loss: 0.0896\t Accuracy: 96.35%\n",
      "[85/100] Training loss: 0.0488\t Validation loss: 0.0893\t Accuracy: 96.35%\n",
      "[90/100] Training loss: 0.0466\t Validation loss: 0.0892\t Accuracy: 96.35%\n",
      "[95/100] Training loss: 0.0446\t Validation loss: 0.0892\t Accuracy: 96.35%\n",
      "[100/100] Training loss: 0.0429\t Validation loss: 0.0895\t Accuracy: 96.35%\n"
     ]
    }
   ],
   "source": [
    "# Setup RNN parameters\n",
    "model_type = 'gru'\n",
    "activation_fun = 'relu'  # note that activation_fun value is irrelevant for GRU and LSTM\n",
    "input_dim = len(input_al)\n",
    "output_dim = len(output_al)\n",
    "hidden_dim = 20\n",
    "layer_dim = 2\n",
    "dropout = 0  # 0.1 if layer_dim > 1 else 0\n",
    "n_epochs = 100\n",
    "optimizer = optim.Adam\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 1e-6\n",
    "early_stop = True  # Stop training if loss is smaller than small threshold for few epochs\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'layer_dim': layer_dim,\n",
    "                'output_dim': output_dim,\n",
    "                'nonlinearity': activation_fun,\n",
    "                'dropout_prob': dropout,\n",
    "                'data_handler': data_handler,\n",
    "                'device': None}\n",
    "\n",
    "model = get_model(model_type, model_params)\n",
    "\n",
    "optimizer = optimizer(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "opt = Optimization(model=model, optimizer=optimizer, device=None)\n",
    "\n",
    "process_hs_fun = 'flatten_lstm' if model_type == 'lstm' else 'flatten'\n",
    "\n",
    "# This will train the RNN\n",
    "# If trained model with same parametrization exists, it will be loaded unless load flag is set to False\n",
    "opt.train(train, val, n_epochs=n_epochs, exp_name=exp_name, early_stop=early_stop, save=True, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639abe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis 1: 6 states.\n",
      "-----------------------------------\n",
      "Learning Finished.\n",
      "Learning Rounds:  1\n",
      "Number of states: 6\n",
      "Time (in seconds)\n",
      "  Total                : 8.49\n",
      "  Learning algorithm   : 1.35\n",
      "  Conformance checking : 7.14\n",
      "Learning Algorithm\n",
      " # Membership Queries  : 600\n",
      " # MQ Saved by Caching : 10\n",
      " # Steps               : 1800\n",
      "Equivalence Query\n",
      " # Membership Queries  : 1000\n",
      " # Steps               : 10000\n",
      "-----------------------------------\n",
      "Visualization started in the background thread.\n",
      "Model saved to LearnedModel.pdf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start : This command cannot be run due to the error: The system cannot find the file specified.\r\n",
      "At line:1 char:1\r\n",
      "+ Start \"file:///home/lone/UTAStuff/adv-spc-infosec/project/rnn/train-r ...\r\n",
      "+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "    + CategoryInfo          : InvalidOperation: (:) [Start-Process], InvalidOperationException\r\n",
      "    + FullyQualifiedErrorId : InvalidOperationException,Microsoft.PowerShell.Commands.StartProcessCommand\r\n",
      " \r\n"
     ]
    }
   ],
   "source": [
    "# disable all gradient computations to speed up execution\n",
    "torch.no_grad()\n",
    "\n",
    "# check the RNN for accuracy on randomly generated data\n",
    "# conformance_test(model, automaton, n_tests=1000, max_test_len=30)\n",
    "\n",
    "# wrap RNN in AALpy's SUL interface\n",
    "sul = RNNSul(model)\n",
    "# this is a weak eq. oracle with weak configuration\n",
    "eq_oracle = RandomWordEqOracle(input_al, sul, num_walks=1000, max_walk_len=10)\n",
    "\n",
    "learned_model = run_Lstar(input_al, sul, eq_oracle, 'mealy')\n",
    "learned_model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb62073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b3356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
